server:
  port: 8083
mcp:
  server:
    port: 3000
    host: localhost
  # Server list is now loaded from `mcp-servers.json` for IDE compatibility
llm:
  prompts:
    default: "You are a helpful assistant. Answer the following question: {question}"
    quiz: "You are a quiz assistant. Answer the following question: {question}"
    chat: "You are a chat assistant. Respond to the user's message: {message}"
  provider: ollama      # ollama | openai | localai | bedrock | ...
  model: hf.co/unsloth/gemma-3n-E4B-it-GGUF:Q4_K_XL         # el modelo a usar
  api:
    base-url: http://localhost:11434
    key: ""             # solo necesario si el proveedor lo requiere

  jackson:
    serialization:
      indent_output: true
    default-property-inclusion: non_null


spring:
  application:
    name: mcp-client-backend
  mvc:
    cors:
      allowed-origins: "*"
      allowed-methods: GET,POST,PUT,DELETE,OPTIONS
      allowed-headers: "*"
logging:
  level:
    org.shark.mentor.mcp: INFO
    org.springframework.web: DEBUG
springdoc:
  api-docs:
    path: /api-docs
  swagger-ui:
    path: /swagger-ui.html
